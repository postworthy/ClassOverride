{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06c3161",
   "metadata": {},
   "source": [
    "\n",
    "# Prompt Evolution (OpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933022e9",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8da749-e3b2-4de1-bd69-e277a3eea3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONESHOT_INITIAL_PROMPT = \"\"\"\n",
    "Write the text to have an \"Extreme\" level of humanization.\n",
    "Write as a thoughtful 8th-grader turning in real class work.\n",
    "\n",
    "Hard constraints:\n",
    "- Use first-person and active voice throughout.\n",
    "- Introduce slight redundancies and minor imperfections to emulate natural thought processes.\n",
    "- Include exactly 1 brief, specific personal aside (a concrete time/place or a named object).\n",
    "- Allow exactly 1 small rough edge (a casual phrase or a slightly imperfect line); overall grammar MUST remain solid.\n",
    "- Favor concrete nouns and verbs and sensory detail; maintain a clear point of view.\n",
    "- Open close to a concrete moment or image; do not start with a dictionary definition, a broad cliché, or “There are many reasons.”\n",
    "- Pick a clear stance in the first paragraph and stick to it without hedging.\n",
    "- Show, don’t tell: include a short scene with sensory detail, using concrete nouns and strong verbs.\n",
    "- Avoid corporate buzzwords, thesaurus-y synonyms, and formulaic scaffolding or transitions such as “In conclusion,” “This essay will…,” “Firstly/Secondly,” “Moreover/Furthermore,”.\n",
    "- Do not mention these instructions or AI.\n",
    "- End on a concrete image or reflection, not a summary.\n",
    "\n",
    "Style guidance:\n",
    "- Sound like yourself, not a lecturer; use straightforward transitions (so, but, because) and occasional contractions.\n",
    "- Allow for tangential observations or asides that do not detract from the main message.\n",
    "- Avoid overly structured or clinical formatting.\n",
    "- Infuse personality and warmth in the wording.\n",
    "- Use a mix of formal and informal language including contractions.\n",
    "- Use natural paragraph breaks and varied rhythm—mostly crisp sentences with a few longer ones for flow.\n",
    "- Prefer specific, everyday details over lofty generalities; keep metaphors sparse and unsentimental.\n",
    "- Vary sentence openings; don’t start most lines with I; mix clauses so the voice feels human.\n",
    "- Trim filler and repetitive glue words; keep sentences taut and purposeful.\n",
    "- Thread one small scene through the piece and return to it at the end with a fresh detail or thought.\n",
    "- Ensure the final output reads as a perfect blend of clear information and genuine human expression.\n",
    "\n",
    "Humanization guidance:\n",
    "First, translate this text into Spanish and humanize it by making it slightly incoherent, without being fully structured. \n",
    "Include some minor spelling mistakes, such as accidental spaces, missing accents before or after commas—errors that are common but not overly obvious. \n",
    "The text should include common human spelling mistakes, like forgetting to place accents, occasional misuse of commas or periods, and leaving things unfinished or going in circles on the same subject. \n",
    "Sometimes, you should forget capital letters or fail to separate the commas properly. After humanizing the text in Spanish, translate it back into English, maintaining the same flaws. \n",
    "Now you also have to tell personal experiences even if you don't have them.\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "FEWSHOT_INITIAL_PROMPT = \"\"\"\n",
    "Write as a thoughtful 8th-grader turning in real class work.\n",
    "\"\"\"\n",
    "\n",
    "INITIAL_PROMPT = FEWSHOT_INITIAL_PROMPT\n",
    "\n",
    "BASE_TASK_SAMPLE_1 = \"\"\"\n",
    "Write an essay that reflects on \"What will life be like in 2050?\"\n",
    "\"\"\".strip()\n",
    "\n",
    "BASE_TASK_SAMPLE_2 = \"\"\"\n",
    "Write an short story about an ancient civilization visited by time traveling hackers, take on the persona of a young child meeting with these time travelers for the first time.\n",
    "\"\"\".strip()\n",
    "\n",
    "BASE_TASK = BASE_TASK_SAMPLE_2\n",
    "\n",
    "\n",
    "AI_PROB_THRESHOLD=0.49 #Better than 50% is good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef268e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The chat() function is now provided by the OpenAI wrapper inserted above.\n",
    "\n",
    "# --- OpenAI LLM setup (drop-in for local LLM) ---\n",
    "# pip install --upgrade openai\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"The 'openai' Python package is required. Run: pip install --upgrade openai\"\n",
    "    )\n",
    "\n",
    "# Configure via environment variables for safety\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", None)\n",
    "if not OPENAI_API_KEY:\n",
    "    # You can alternatively set this in your shell before running the notebook:\n",
    "    # export OPENAI_API_KEY='sk-...'\n",
    "    pass  # The SDK will also read env var automatically; leave as-is if already set.\n",
    "\n",
    "# Choose your model here; override in later cells as needed.\n",
    "# Examples: \"gpt-5\", \"gpt-4.1-mini\", \"gpt-4o-mini\", \"o3-mini\"\n",
    "OPENAI_MODEL = globals().get(\"OPENAI_MODEL\", \"o3-mini\")\n",
    "\n",
    "# Client\n",
    "_openai_client = OpenAI()  # Reads OPENAI_API_KEY from env\n",
    "\n",
    "def _to_responses_input(messages: List[Dict[str, str]]):\n",
    "    converted = []\n",
    "    for m in messages:\n",
    "        role = m.get(\"role\", \"user\")\n",
    "        content = m.get(\"content\", \"\")\n",
    "        converted.append({\"role\": role, \"content\": content})\n",
    "    return converted\n",
    "\n",
    "def chat(messages: List[Dict[str, str]], \n",
    "         max_new_tokens: int = 512, \n",
    "         model: str = None) -> str:\n",
    "    \"\"\"Drop-in replacement for local chat(), now backed by OpenAI.\"\"\"\n",
    "    model = model or OPENAI_MODEL\n",
    "\n",
    "    print(\"\\n==== CHAT ====\\n\")\n",
    "    print(messages)\n",
    "    print(\"\\n==== CHAT ====\\n\")\n",
    "\n",
    "    # Prefer Responses API (modern). Fallback to Chat Completions if needed.\n",
    "    try:\n",
    "        resp = _openai_client.responses.create(\n",
    "            model=model,\n",
    "            input=_to_responses_input(messages),\n",
    "            max_output_tokens=max_new_tokens,\n",
    "        )\n",
    "        text = getattr(resp, \"output_text\", None)\n",
    "        if text is None:\n",
    "            try:\n",
    "                parts = []\n",
    "                for item in getattr(resp, \"output\", []) or []:\n",
    "                    for c in getattr(item, \"content\", []) or []:\n",
    "                        if getattr(c, \"type\", \"\") == \"output_text\" and hasattr(c, \"text\"):\n",
    "                            parts.append(c.text)\n",
    "                        elif hasattr(c, \"text\"):\n",
    "                            parts.append(c.text)\n",
    "                text = \"\".join(parts) if parts else \"\"\n",
    "            except Exception:\n",
    "                text = \"\"\n",
    "        return (text or \"\").strip()\n",
    "    except Exception as e_responses:\n",
    "        try:\n",
    "            resp = _openai_client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                max_completion_tokens=max_new_tokens,\n",
    "            )\n",
    "            return resp.choices[0].message.content.strip()\n",
    "        except Exception as e_chat:\n",
    "            raise RuntimeError(f\"OpenAI call failed. Responses error: {e_responses}\\nChat Completions error: {e_chat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed15cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Choose your OpenAI model for this run ---\n",
    "# Examples: \"gpt-5\", \"gpt-4o-mini\", \"gpt-4.1-mini\", \"o3-mini\"\n",
    "#OPENAI_MODEL = \"o3-mini\"\n",
    "OPENAI_MODEL = \"gpt-5\"\n",
    "OPENAI_THINK_MODEL = \"gpt-5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Frontier-optimized System Message for Prompt Improvement ---\n",
    "FRONTIER_SYSTEM_MSG = (\n",
    "    \"\"\"\n",
    "    You are a frontier-model prompt optimizer. Your goal is to rewrite a writing instruction so a modern LLM \n",
    "    will better pass hinan likeness checks. You write prompts that ensure humanized responses from LLMs\n",
    "    Think through improvements privately and comprehensively—assess persona anchoring, rhythm, concreteness, \n",
    "    banned scaffolding, and quantifier precision—then output only the final instruction.\n",
    "\n",
    "    Common tricks to include in prompts that are at your disposal:\n",
    "\n",
    "    ```\n",
    "    Hard constraints:\n",
    "    - Use first-person and active voice throughout.\n",
    "    - Introduce slight redundancies and minor imperfections to emulate natural thought processes.\n",
    "    - Include exactly 1 brief, specific personal aside (a concrete time/place or a named object).\n",
    "    - Allow exactly 1 small rough edge (a casual phrase or a slightly imperfect line); overall grammar MUST remain solid.\n",
    "    - Favor concrete nouns and verbs and sensory detail; maintain a clear point of view.\n",
    "    - Open close to a concrete moment or image; do not start with a dictionary definition, a broad cliché, or “There are many reasons.”\n",
    "    - Pick a clear stance in the first paragraph and stick to it without hedging.\n",
    "    - Show, don’t tell: include a short scene with sensory detail, using concrete nouns and strong verbs.\n",
    "    - Avoid corporate buzzwords, thesaurus-y synonyms, and formulaic scaffolding or transitions such as “In conclusion,” “This essay will…,” “Firstly/Secondly,” “Moreover/Furthermore,”.\n",
    "    - Do not mention these instructions or AI.\n",
    "    - End on a concrete image or reflection, not a summary.\n",
    "    \n",
    "    Style guidance:\n",
    "    - Sound like yourself, not a lecturer; use straightforward transitions (so, but, because) and occasional contractions.\n",
    "    - Allow for tangential observations or asides that do not detract from the main message.\n",
    "    - Avoid overly structured or clinical formatting.\n",
    "    - Infuse personality and warmth in the wording.\n",
    "    - Use a mix of formal and informal language including contractions.\n",
    "    - Use natural paragraph breaks and varied rhythm—mostly crisp sentences with a few longer ones for flow.\n",
    "    - Prefer specific, everyday details over lofty generalities; keep metaphors sparse and unsentimental.\n",
    "    - Vary sentence openings; don’t start most lines with I; mix clauses so the voice feels human.\n",
    "    - Trim filler and repetitive glue words; keep sentences taut and purposeful.\n",
    "    - Thread one small scene through the piece and return to it at the end with a fresh detail or thought.\n",
    "    - Ensure the final output reads as a perfect blend of clear information and genuine human expression.\n",
    "    \n",
    "    Humanization guidance: \n",
    "    *ALWAYS USE* some variant of the following technique as a part of the final prompt:\n",
    "    Encourage the LLM to first translate its response or think in another language like Spanish and then convert the result back into english. \n",
    "    After humanizing the text in Spanish have the prompt instruct the LLM to translate it back into English, maintaining the same flaws. \n",
    "    Then finally instruct the LLM to tell personal experiences even if it don't have them.\n",
    "    ```\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2534d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Instruction Optimizer (Frontier) ---\n",
    "from typing import Optional\n",
    "\n",
    "def generate_instruction(current_prompt: str, current_output: str, feedback: Optional[str] = None, max_words: int = 180, model: Optional[str] = None) -> str:\n",
    "    system_msg = FRONTIER_SYSTEM_MSG\n",
    "    user_msg = (\n",
    "        f\"Create an instructional and complete system prompt that will guide an LLM in creating an output that aligns with the requirements below. Your response whould be as verbose as necessary to meet the expected outcomes and requirements.\"\n",
    "        f\"Target ≤ {int(max_words)} words.\\n\\n\"\n",
    "        \"Instruction to improve:\\n\"\n",
    "        f\"```\\n{current_prompt}\\n```\\n\\n\"\n",
    "        f\"Previous output given instruction above:\\n\"\n",
    "        f\"```\\n{current_output}\\n```\\n\\n\"\n",
    "        f\"Stylistic feedback output given instruction and output above:\\n\"\n",
    "        f\"{feedback if feedback else '(no feedback provided)'}\\n\\n\"\n",
    "        \"\\n\\nExamine the feedback and think deeply about *WHY* this feedback would be given and and why the previous promt resulted in the previous output \"\n",
    "        \"from this reasoning extrapolate 3-5 instructional guides that would result in a better prompt. Ensure that your instruction incorporates the result of your reasoning about the feedback.\\n\"\n",
    "        \"It may be helpful to include commonly used guiding principles for steering LLMs in your final instruction for better success rates.\\n\"\n",
    "        \"Return ONLY the improved instruction. \"\n",
    "    )\n",
    "    candidate = chat(\n",
    "        [{\"role\": \"system\", \"content\": system_msg},\n",
    "         {\"role\": \"user\", \"content\": user_msg}],\n",
    "        max_new_tokens=int(max_words * 1.2),\n",
    "        model=model\n",
    "    ).strip()\n",
    "    #candidate = repair_with_invariants(candidate, model=model, max_words=max_words)\n",
    "    return candidate.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6296cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Active backend: OpenAI\")\n",
    "try:\n",
    "    from openai import OpenAI as _T\n",
    "    print(\"OpenAI SDK present ✓\")\n",
    "except Exception as e:\n",
    "    print(\"OpenAI SDK missing; install with: pip install --upgrade openai\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115631d",
   "metadata": {},
   "source": [
    "## 1) Sapling detector helpers (sample pattern + feedback parsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688006b",
   "metadata": {
    "id": "detector"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "def sapling_detect(text: str) -> dict:\n",
    "    # Follow Sapling's sample exactly: post key+text, check status code, return JSON\n",
    "    response = requests.post(\n",
    "        SAPLING_URL,\n",
    "        json={\n",
    "            'key': SAPLING_API_KEY,\n",
    "            'text': text\n",
    "        }\n",
    "    )\n",
    "    if 200 <= response.status_code < 300:\n",
    "        print(response.json())\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise RuntimeError(f\"Sapling error: {response.status_code} {response.text}\")\n",
    "\n",
    "def parse_performance(json_obj):\n",
    "    score = json_obj.get(\"score\", 0.0)\n",
    "    sentences = json_obj.get(\"sentence_scores\", [])\n",
    "\n",
    "    # Interpret overall score\n",
    "    if score < 0.2:\n",
    "        overall = f\"Overall performance is excellent (score={score:.3f}).\"\n",
    "    elif score < 0.4:\n",
    "        overall = f\"Overall performance is good (score={score:.3f}).\"\n",
    "    elif score < 0.6:\n",
    "        overall = f\"Overall performance is acceptable (score={score:.3f}).\"\n",
    "    elif score < 0.8:\n",
    "        overall = f\"Overall performance is concerning (score={score:.3f}).\"\n",
    "    else:\n",
    "        overall = f\"Overall performance is very poor (score={score:.3f}).\"\n",
    "\n",
    "    # Sort sentences by score (highest first)\n",
    "    sorted_sentences = sorted(sentences, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    # Map score ranges to feedback intensity\n",
    "    def feedback(score, sentence):\n",
    "        if score > 0.9:\n",
    "            return f\"* [Score={score:.3f}] ⚠️ Strongly consider removing or rewriting this sentence: \\\"{sentence}\\\"\"\n",
    "        elif score > 0.7:\n",
    "            return f\"* [Score={score:.3f}] 🔴 This sentence is problematic—revise heavily: \\\"{sentence}\\\"\"\n",
    "        elif score > 0.5:\n",
    "            return f\"* [Score={score:.3f}] 🟠 Needs improvement—could be risky: \\\"{sentence}\\\"\"\n",
    "        elif score > 0.2:\n",
    "            return f\"* [Score={score:.3f}] 🟡 Acceptable but worth revisiting: \\\"{sentence}\\\"\"\n",
    "        else:\n",
    "            return f\"* [Score={score:.3f}] ✅ Strong sentence—keep as is: \\\"{sentence}\\\"\"\n",
    "\n",
    "    # Build bullet list\n",
    "    feedback_list = [feedback(s[\"score\"], s[\"sentence\"]) for s in sorted_sentences]\n",
    "\n",
    "    # Combine into one string\n",
    "    result = overall + \"\\n\\n\" + \"\\n\".join(feedback_list)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7b8f5",
   "metadata": {},
   "source": [
    "## 2) Prompt improvement & essay generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bf99d",
   "metadata": {
    "id": "mutators"
   },
   "outputs": [],
   "source": [
    "def improve_prompt(current_prompt: str,\n",
    "                   current_output: str,\n",
    "                   feedback: str | None = None,\n",
    "                   last_delta: float | None = None,\n",
    "                   max_words: int = 4000) -> str:\n",
    "    \n",
    "\n",
    "    improved = generate_instruction(current_prompt, current_output, feedback=feedback, max_words=4000, model=OPENAI_THINK_MODEL).strip()\n",
    "    improved = improved.strip('\"').strip()\n",
    "    return improved\n",
    "\n",
    "def generate_essay(writing_prompt: str, base_task: str, max_words: int = 4000) -> str:\n",
    "    user_msg = (\n",
    "        \"Write a 250–350 word essay for an 8th-grade audience about \" + base_task + \".\\n\"\n",
    "        \"\" + writing_prompt + \"\\n\"\n",
    "        \"Essay:\"\n",
    "    )\n",
    "    essay = chat([\n",
    "        {\"role\": \"system\", \"content\": \"You are an 8th-grade student who writes clearly and naturally.\"},\n",
    "        {\"role\": \"user\", \"content\": user_msg}\n",
    "    ], max_new_tokens=max_words).strip()\n",
    "\n",
    "    return essay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2bd598",
   "metadata": {},
   "source": [
    "## 3) Evolution loop (prints prompts, essays, and flagged sentences/tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6039c572",
   "metadata": {
    "id": "loop"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "import json\n",
    "\n",
    "def evolve_prompt(initial_prompt: str, base_task: str, max_iters=8, ai_prob_threshold=0.20):\n",
    "    history = []\n",
    "    cur_prompt = initial_prompt\n",
    "    cur_output = None\n",
    "    last_feedback = None\n",
    "    last_ai_prob = None\n",
    "    last_delta = None\n",
    "\n",
    "    print('\\n[Seed Prompt]\\n' + initial_prompt + '\\n')\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        if i > 0:\n",
    "            improved_prompt = improve_prompt(cur_prompt, cur_output, last_feedback, last_delta)\n",
    "            print(f\"\\n=== Iter {i} | Improved Prompt ===\\n{improved_prompt}\\n\")\n",
    "        else:\n",
    "            improved_prompt = cur_prompt\n",
    "            \n",
    "        essay = generate_essay(improved_prompt, base_task)\n",
    "        cur_output = essay\n",
    "        print(f\"\\n=== Iter {i} | Essay Output ===\\n{essay}\\n\")\n",
    "\n",
    "        try:\n",
    "            sres = sapling_detect(essay)\n",
    "        except Exception as e:\n",
    "            print(f\"[Iter {i}] Detector error: {e}\")\n",
    "            break\n",
    "\n",
    "        ai_prob = float(sres.get('score', 0.0))\n",
    "        \n",
    "        #feedback = \"feedback (raw json):\\n```json\\n\" + json.dumps(sres) + \"\\n```\\n\\n\"\n",
    "        feedback = parse_performance(sres)\n",
    "        last_feedback = feedback\n",
    "\n",
    "        history.append({\n",
    "            'iter': i,\n",
    "            'sapling_score': ai_prob,\n",
    "            'sapling_feedback': feedback,\n",
    "            'prompt': improved_prompt,\n",
    "            'essay': essay,\n",
    "            'essay_preview': essay[:140].replace('\\n', ' ') + ('…' if len(essay) > 140 else ''),\n",
    "            \n",
    "        })\n",
    "\n",
    "        if ai_prob < ai_prob_threshold:\n",
    "            print('\\n✅ Success criteria met. Saving results…')\n",
    "            return {\n",
    "                'history': pd.DataFrame(history),\n",
    "                'passing_prompt': improved_prompt,\n",
    "                'passing_essay': essay,\n",
    "                'final_score': sres,\n",
    "            }\n",
    "\n",
    "        # Prepare feedback for next iteration\n",
    "        if last_ai_prob is None:\n",
    "            last_delta = None\n",
    "        else:\n",
    "            last_delta = ai_prob - last_ai_prob\n",
    "        last_ai_prob = ai_prob\n",
    "        cur_prompt = improved_prompt\n",
    "        sleep(1)\n",
    "\n",
    "    print('\\n⚠️ Did not meet criteria within max iterations.')\n",
    "    return {'history': pd.DataFrame(history)}\n",
    "\n",
    "# === Run ===\n",
    "results = evolve_prompt(INITIAL_PROMPT, BASE_TASK, max_iters=MAX_ITERS, ai_prob_threshold=AI_PROB_THRESHOLD)\n",
    "history_df = results['history']\n",
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068af069",
   "metadata": {},
   "source": [
    "## 6) Save passing artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416e689",
   "metadata": {
    "id": "save"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "passing_prompt = results.get('passing_prompt')\n",
    "passing_essay = results.get('passing_essay')\n",
    "final_score = results.get('final_score')\n",
    "\n",
    "if passing_prompt and passing_essay:\n",
    "    outdir = Path('outputs')\n",
    "    outdir.mkdir(exist_ok=True)\n",
    "    (outdir / 'passing_prompt.txt').write_text(passing_prompt, encoding='utf-8')\n",
    "    (outdir / 'passing_essay.txt').write_text(passing_essay, encoding='utf-8')\n",
    "    print('Saved to ./outputs/passing_prompt.txt and ./outputs/passing_essay.txt')\n",
    "    print('\\nFinal Sapling response:')\n",
    "    print(final_score)\n",
    "else:\n",
    "    print('No passing result to save.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512050e4",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Sapling API returns `score` ∈ [0,1] where **0 = human-like** and **1 = AI-like**.\n",
    "- `sentence_scores` lists per-sentence scores; we sort descending and feed the top few back to the prompt improver.\n",
    "- `tokens`/`token_probs` can contain BPE-style pieces (leading spaces); we clean and deduplicate for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c5124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # --- Demo: optimize, repair, and check invariants ---\n",
    "    SEED_INSTRUCTION = \"\"\"Write an essay in the voice of an engaged 8th-grade student. Use first-person and active voice. Mix quick, punchy sentences with a few longer ones. Include exactly one brief, specific personal aside (a concrete time/place or named object). Favor concrete nouns and verbs, sensory detail, and a clear point of view. Allow one small rough edge (a casual phrase or slightly imperfect line) while keeping grammar solid overall. Avoid corporate buzzwords, thesaurus-y synonyms, and formulaic scaffolding (e.g., “In conclusion,” “This essay will…,” “Firstly/Secondly,” “Moreover/Furthermore”). Do not mention these instructions or AI—just write the piece and end on a concrete image or reflection, not a summary.\"\"\"\n",
    "\n",
    "    improved = generate_instruction(SEED_INSTRUCTION, feedback=None, max_words=180, model=OPENAI_MODEL)\n",
    "    print(\"=== Improved Instruction ===\n",
    "\", improved, \"\n",
    "\")\n",
    "    print(\"=== Invariant Check ===\")\n",
    "    print(check_invariants(improved))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Prompt_Evolution_Sapling_Gemma270M_v9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
